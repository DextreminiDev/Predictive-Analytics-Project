{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "81b7d4f8-ca78-4c2e-ac7c-281b9bcbbca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "32f9c6c7-9420-4724-9c24-a5aabbd558e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6765 images belonging to 4 classes.\n",
      "Found 1690 images belonging to 4 classes.\n",
      "Epoch 1/10\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 277ms/step - accuracy: 0.4381 - loss: 1.1676 - val_accuracy: 0.4817 - val_loss: 1.2911\n",
      "Epoch 2/10\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 179ms/step - accuracy: 0.6996 - loss: 0.7193 - val_accuracy: 0.5118 - val_loss: 1.5299\n",
      "Epoch 3/10\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 186ms/step - accuracy: 0.7977 - loss: 0.4912 - val_accuracy: 0.5231 - val_loss: 1.8068\n",
      "Epoch 4/10\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 176ms/step - accuracy: 0.8786 - loss: 0.3199 - val_accuracy: 0.5308 - val_loss: 1.6851\n",
      "Epoch 5/10\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 177ms/step - accuracy: 0.9124 - loss: 0.2409 - val_accuracy: 0.5036 - val_loss: 2.2362\n",
      "Epoch 6/10\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 186ms/step - accuracy: 0.9348 - loss: 0.1861 - val_accuracy: 0.5166 - val_loss: 2.4746\n",
      "Epoch 7/10\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 198ms/step - accuracy: 0.9585 - loss: 0.1264 - val_accuracy: 0.4911 - val_loss: 3.0490\n",
      "Epoch 8/10\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 170ms/step - accuracy: 0.9650 - loss: 0.0981 - val_accuracy: 0.5047 - val_loss: 3.1027\n",
      "Epoch 9/10\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 175ms/step - accuracy: 0.9821 - loss: 0.0653 - val_accuracy: 0.5130 - val_loss: 3.8542\n",
      "Epoch 10/10\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 174ms/step - accuracy: 0.9866 - loss: 0.0469 - val_accuracy: 0.5065 - val_loss: 3.8851\n"
     ]
    }
   ],
   "source": [
    "# Part 2: Create Smaller Dataset\n",
    "def create_smaller_dataset(source_dir, dest_dir, num_images_per_class=250):\n",
    "    if not os.path.exists(dest_dir):\n",
    "        os.makedirs(dest_dir)\n",
    "\n",
    "    for class_dir in os.listdir(source_dir):\n",
    "        class_path = os.path.join(source_dir, class_dir)\n",
    "        dest_class_path = os.path.join(dest_dir, class_dir)\n",
    "        \n",
    "        if not os.path.exists(dest_class_path):\n",
    "            os.makedirs(dest_class_path)\n",
    "        \n",
    "        images = os.listdir(class_path)\n",
    "        random.shuffle(images)\n",
    "        selected_images = images[:num_images_per_class]\n",
    "        \n",
    "        for img in selected_images:\n",
    "            src_img_path = os.path.join(class_path, img)\n",
    "            dest_img_path = os.path.join(dest_class_path, img)\n",
    "            shutil.copy(src_img_path, dest_img_path)\n",
    "\n",
    "# Load treatments from text files\n",
    "def load_treatment(stage):\n",
    "    file_path = os.path.join(r\"C:\\Users\\tanis\\OneDrive - UPES\\datasets\\preditive analysis lab\\treatment_files\", f\"{stage}.txt\")\n",
    "    with open(file_path, \"r\") as file:\n",
    "        return file.read()\n",
    "\n",
    "# Prepare data from the smaller dataset\n",
    "def prepare_data(image_directory):\n",
    "    # Example using ImageDataGenerator for loading images\n",
    "    datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)  # Normalize and split data\n",
    "\n",
    "    train_generator = datagen.flow_from_directory(\n",
    "        image_directory,\n",
    "        target_size=(64, 64),  # Reduced image size for faster training\n",
    "        batch_size=64,  # Increased batch size\n",
    "        class_mode='categorical',\n",
    "        subset='training'\n",
    "    )\n",
    "    \n",
    "    validation_generator = datagen.flow_from_directory(\n",
    "        image_directory,\n",
    "        target_size=(64, 64),  # Reduced image size for faster training\n",
    "        batch_size=64,  # Increased batch size\n",
    "        class_mode='categorical',\n",
    "        subset='validation'\n",
    "    )\n",
    "    \n",
    "    return train_generator, validation_generator\n",
    "\n",
    "# Main setup\n",
    "def setup():\n",
    "    # Set source and destination directories\n",
    "    source_directory = r\"C:\\Users\\tanis\\OneDrive - UPES\\datasets\\preditive analysis lab\\Data\"\n",
    "    destination_directory = r\"C:\\Users\\tanis\\OneDrive - UPES\\datasets\\preditive analysis lab\\Data_small\"\n",
    "    \n",
    "    # Create a smaller dataset with 250 images per class (total of 1000 images)\n",
    "    create_smaller_dataset(source_directory, destination_directory, num_images_per_class=250)\n",
    "\n",
    "    # Prepare the reduced data for training\n",
    "    image_directory = destination_directory\n",
    "    train_data, val_data = prepare_data(image_directory)\n",
    "\n",
    "    # Create CNN model\n",
    "    input_shape = (64, 64, 3)  # Reduced image size\n",
    "    model = create_cnn_model(input_shape)\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model, train_data, val_data\n",
    "\n",
    "def create_cnn_model(input_shape):\n",
    "    model = models.Sequential()\n",
    "    \n",
    "    # Convolutional layers\n",
    "    model.add(layers.Conv2D(16, (3, 3), activation='relu', input_shape=input_shape))  # Reduced filters\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    model.add(layers.Conv2D(32, (3, 3), activation='relu'))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    model.add(layers.Conv2D(32, (3, 3), activation='relu'))\n",
    "    \n",
    "    # Flatten and Dense layers\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(64, activation='relu'))\n",
    "    model.add(layers.Dense(4, activation='softmax'))  # 4 classes: non-demented, very mild, mild, moderate\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Part 3: Train the Model\n",
    "def train_model(model, train_data, val_data):\n",
    "    # Train the model on the smaller dataset\n",
    "    model.fit(train_data, epochs=10, validation_data=val_data)\n",
    "    return model\n",
    "\n",
    "# Call setup and train\n",
    "if __name__ == \"__main__\":\n",
    "    model, train_data, val_data = setup()\n",
    "    trained_model = train_model(model, train_data, val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "571a62d2-f7e6-47a7-b205-0508fc77403b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step\n"
     ]
    }
   ],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import filedialog, messagebox\n",
    "from tkinter import ttk\n",
    "\n",
    "# Predict image and load treatment\n",
    "def predict_image(image_path):\n",
    "    img = tf.keras.preprocessing.image.load_img(image_path, target_size=(64, 64))\n",
    "    img_array = tf.keras.preprocessing.image.img_to_array(img) / 255.0\n",
    "    img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension\n",
    "    \n",
    "    # Make a prediction\n",
    "    prediction = model.predict(img_array)\n",
    "    class_index = np.argmax(prediction)\n",
    "    \n",
    "    # Map prediction to stage using exact folder names\n",
    "    classes = ['Non Demented', 'Very Mild Dementia', 'Mild Dementia', 'Moderate Dementia']\n",
    "    predicted_stage = classes[class_index]\n",
    "    \n",
    "    # Load treatment based on classification\n",
    "    treatment = load_treatment(predicted_stage)\n",
    "    \n",
    "    # Return predicted stage and probabilities\n",
    "    return predicted_stage, prediction[0]\n",
    "\n",
    "# Update the GUI with prediction results\n",
    "def update_prediction():\n",
    "    if not image_path.get():\n",
    "        messagebox.showwarning(\"Warning\", \"Please select an image first.\")\n",
    "        return\n",
    "\n",
    "    predicted_stage, probabilities = predict_image(image_path.get())\n",
    "    \n",
    "    # Update label with predicted stage and treatment\n",
    "    prediction_label.config(text=f\"Predicted Stage: {predicted_stage}\", font=(\"Arial\", 14, \"bold\"))\n",
    "    treatment_label.config(text=f\"Recommended Treatment: \\n{load_treatment(predicted_stage)}\", font=(\"Arial\", 12))\n",
    "    \n",
    "    # Update progress bars\n",
    "    for i, class_name in enumerate(['Non Demented', 'Very Mild Dementia', 'Mild Dementia', 'Moderate Dementia']):\n",
    "        progress_var[i].set(probabilities[i])\n",
    "        progress_bar[i].config(maximum=1, value=probabilities[i])\n",
    "        progress_label[i].config(text=f\"{class_name}: {probabilities[i]:.2f}\", font=(\"Arial\", 10))\n",
    "\n",
    "# Open file dialog to select image\n",
    "def select_image():\n",
    "    file_path = filedialog.askopenfilename(filetypes=[(\"Image Files\", \"*.jpg;*.jpeg;*.png\")])\n",
    "    if file_path:\n",
    "        image_path.set(file_path)\n",
    "\n",
    "# Clear the input and reset the GUI\n",
    "def clear_input():\n",
    "    image_path.set(\"\")\n",
    "    prediction_label.config(text=\"\")\n",
    "    treatment_label.config(text=\"\")\n",
    "    for i in range(4):\n",
    "        progress_var[i].set(0)\n",
    "        progress_bar[i].config(value=0)\n",
    "        progress_label[i].config(text=\"\")\n",
    "\n",
    "# Initialize the GUI\n",
    "root = tk.Tk()\n",
    "root.title(\"Brain Image Classifier\")\n",
    "root.geometry(\"500x600\")\n",
    "root.configure(bg='#f0f0f5')\n",
    "\n",
    "# Variable to hold image path\n",
    "image_path = tk.StringVar()\n",
    "\n",
    "# Create UI elements\n",
    "header_label = tk.Label(root, text=\"Brain Image Classifier\", font=(\"Arial\", 18, \"bold\"), bg='#f0f0f5')\n",
    "header_label.pack(pady=10)\n",
    "\n",
    "tk.Label(root, text=\"Select an Image to Classify:\", font=(\"Arial\", 12), bg='#f0f0f5').pack(pady=10)\n",
    "image_entry = tk.Entry(root, textvariable=image_path, width=50, font=(\"Arial\", 10))\n",
    "image_entry.pack(pady=5)\n",
    "\n",
    "select_button = tk.Button(root, text=\"Select Image\", command=select_image, bg=\"#4CAF50\", fg=\"white\", font=(\"Arial\", 12))\n",
    "select_button.pack(pady=5)\n",
    "\n",
    "predict_button = tk.Button(root, text=\"Predict\", command=update_prediction, bg=\"#2196F3\", fg=\"white\", font=(\"Arial\", 12))\n",
    "predict_button.pack(pady=5)\n",
    "\n",
    "clear_button = tk.Button(root, text=\"Clear\", command=clear_input, bg=\"#f44336\", fg=\"white\", font=(\"Arial\", 12))\n",
    "clear_button.pack(pady=5)\n",
    "\n",
    "prediction_label = tk.Label(root, text=\"\", font=(\"Arial\", 12), bg='#f0f0f5')\n",
    "prediction_label.pack(pady=10)\n",
    "\n",
    "treatment_label = tk.Label(root, text=\"\", font=(\"Arial\", 12), bg='#f0f0f5')\n",
    "treatment_label.pack(pady=10)\n",
    "\n",
    "# Progress bars for each class\n",
    "progress_var = [tk.DoubleVar() for _ in range(4)]\n",
    "progress_bar = []\n",
    "progress_label = []\n",
    "\n",
    "progress_frame = ttk.Frame(root)\n",
    "progress_frame.pack(pady=20, fill=tk.X, padx=10)\n",
    "\n",
    "tk.Label(progress_frame, text=\"Classification Probabilities:\", font=(\"Arial\", 14, \"bold\")).pack(anchor='w')\n",
    "\n",
    "for i, class_name in enumerate(['Non Demented', 'Very Mild Dementia', 'Mild Dementia', 'Moderate Dementia']):\n",
    "    frame = ttk.Frame(progress_frame)\n",
    "    frame.pack(pady=5, fill=tk.X)\n",
    "\n",
    "    bar = ttk.Progressbar(frame, variable=progress_var[i], maximum=1, length=300)\n",
    "    bar.pack(side=tk.LEFT, fill=tk.X, expand=True, padx=5)\n",
    "\n",
    "    label = tk.Label(frame, text=\"\", font=(\"Arial\", 10))\n",
    "    label.pack(side=tk.LEFT, padx=10)\n",
    "    progress_bar.append(bar)\n",
    "    progress_label.append(label)\n",
    "\n",
    "root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc2ca1a-94b0-40d9-81df-adaacd14c71b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
